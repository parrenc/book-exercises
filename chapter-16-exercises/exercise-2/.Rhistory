library(dplyr)
# The data frame `flights` should now be accessible to you.
# Use functions to inspect it: how many rows and columns does it have?
# What are the names of the columns?
# Use `??flights` to search for documentation on the data set (for what the
# columns represent)
nrow(flights)
ncol(flights)
colnames(flights)
?flights
# Use `dplyr` to give the data frame a new column that is the amount of time
# gained or lost while flying (that is: how much of the delay arriving occured
# during flight, as opposed to before departing).
flights <- mutate(flights, gain_in_air = arr_delay - dep_delay)
# Use `dplyr` to sort your data frame in descending order by the column you just
# created. Remember to save this as a variable (or in the same one!)
flights <- arrange(flights, desc(gain_in_air))
View(head(flights))
# For practice, repeat the last 2 steps in a single statement using the pipe
# operator. You can clear your environmental variables to "reset" the data frame
flights <- flights %>% mutate(gain_in_air = arr_delay - dep_delay) %>% arrange(desc(gain_in_air))
# Make a histogram of the amount of time gained using the `hist()` function
hist(flights$gain_in_air)
# On average, did flights gain or lose time?
# Note: use the `na.rm = TRUE` argument to remove NA values from your aggregation
mean(flights$gain_in_air, na.rm = TRUE) # Gained 5 minutes!
# Create a data.frame of flights headed to SeaTac ('SEA'), only including the
# origin, destination, and the "gain_in_air" column you just created
to_sea <- flights %>% select(origin, dest, gain_in_air) %>% filter(dest == "SEA")
# On average, did flights to SeaTac gain or loose time?
mean(to_sea$gain_in_air, na.rm = TRUE) # Gained 11 minutes!
# Consider flights from JFK to SEA. What was the average, min, and max air time
# of those flights? Bonus: use pipes to answer this question in one statement
# (without showing any other data)!
filter(flights, origin == "JFK", dest == "SEA") %>%
summarize(
avg_air_time = mean(air_time, na.rm = TRUE),
max_air_time = max(air_time, na.rm = TRUE),
min_air_time = min(air_time, na.rm = TRUE)
)
# Exercise 5: dplyr grouped operations
# Install the `"nycflights13"` package. Load (`library()`) the package.
# You'll also need to load `dplyr`
# install.packages("nycflights13")  # should be done already
library("nycflights13")
library("dplyr")
# What was the average departure delay in each month?
# Save this as a data frame `dep_delay_by_month`
# Hint: you'll have to perform a grouping operation then summarizing your data
dep_delay_by_month <- flights %>%
group_by(month) %>%
summarize(delay = mean(dep_delay, na.rm = TRUE))
dep_delay_by_month
# Which month had the greatest average departure delay?
filter(dep_delay_by_month, delay == max(delay)) %>% select(month)
# If your above data frame contains just two columns (e.g., "month", and "delay"
# in that order), you can create a scatterplot by passing that data frame to the
# `plot()` function
plot(dep_delay_by_month)
# To which destinations were the average arrival delays the highest?
# Hint: you'll have to perform a grouping operation then summarize your data
# You can use the `head()` function to view just the first few rows
arr_delay_by_month <- flights %>%
group_by(dest) %>%
summarise(delay = mean(arr_delay, na.rm = TRUE)) %>%
arrange(-delay)
head(arr_delay_by_month)
# You can look up these airports in the `airports` data frame!
filter(airports, faa == arr_delay_by_month$dest[1]) # for example
# Which city was flown to with the highest average speed?
city_fasted_speed <- flights %>%
mutate(speed = distance / air_time * 60) %>%
group_by(dest) %>%
summarise(avg_speed = mean(speed, na.rm = TRUE)) %>%
filter(avg_speed == max(avg_speed, na.rm = TRUE))
city_fasted_speed
# Exercise 6: dplyr join operations
# Install the `"nycflights13"` package. Load (`library()`) the package.
# You'll also need to load `dplyr`
# install.packages("nycflights13")  # should be done already
library("nycflights13")
library("dplyr")
# Create a dataframe of the average arrival delays for each _destination_, then
# use `left_join()` to join on the "airports" dataframe, which has the airport
# information
# Which airport had the largest average arrival delay?
largest_arrival_delay <- flights %>%
group_by(dest) %>%
summarise(avg_delay = mean(arr_delay, na.rm = TRUE)) %>%
mutate(faa = dest) %>%
left_join(airports, by = "faa") %>%
filter(avg_delay == max(avg_delay, na.rm = TRUE))
largest_arrival_delay
# Create a dataframe of the average arrival delay for each _airline_, then use
# `left_join()` to join on the "airlines" dataframe
# Which airline had the smallest average arrival delay?
smallest_airline_delay <- flights %>%
group_by(carrier) %>%
summarise(avg_delay = mean(arr_delay, na.rm = TRUE)) %>%
left_join(airlines, by = "carrier") %>%
filter(avg_delay == max(avg_delay, na.rm = TRUE))
smallest_airline_delay
# Exercise 6: dplyr join operations
# Install the `"nycflights13"` package. Load (`library()`) the package.
# You'll also need to load `dplyr`
# install.packages("nycflights13")  # should be done already
library("nycflights13")
library("dplyr")
# Create a dataframe of the average arrival delays for each _destination_, then
# use `left_join()` to join on the "airports" dataframe, which has the airport
# information
# Which airport had the largest average arrival delay?
largest_arrival_delay <- flights %>%
group_by(dest) %>%
summarise(avg_delay = mean(arr_delay, na.rm = TRUE)) %>%
mutate(faa = dest) %>%
left_join(airports, by = "faa") %>%
filter(avg_delay == max(avg_delay, na.rm = TRUE))
largest_arrival_delay
# Create a dataframe of the average arrival delay for each _airline_, then use
# `left_join()` to join on the "airlines" dataframe
# Which airline had the smallest average arrival delay?
smallest_airline_delay <- flights %>%
group_by(carrier) %>%
summarise(avg_delay = mean(arr_delay, na.rm = TRUE)) %>%
left_join(airlines, by = "carrier") %>%
filter(avg_delay == max(avg_delay, na.rm = TRUE))
smallest_airline_delay
load("dplyr")
Sys.setlocale("LC_ALL", "English")
# Create a list of the three pieces of information from above.
# Print out the list.
review <- list(headline=headline, summary=summary, link=link)
# load relevant libraries
library("httr")
library("jsonlite")
# Be sure and check the README.md for complete instructions!
# Use `source()` to load your API key variable from the `apikey.R` file you made.
# Make sure you've set your working directory!
source("apikey.R")
# Create a variable `movie_name` that is the name of a movie of your choice.
movie_name <- "Star Wars"
# Construct an HTTP request to search for reviews for the given movie.
# The base URI is `https://api.nytimes.com/svc/movies/v2/`
# The resource is `reviews/search.json`
# See the interactive console for parameter details:
#   https://developer.nytimes.com/movie_reviews_v2.json
#
# You should use YOUR api key (as the `api-key` parameter)
# and your `movie_name` variable as the search query!
base_uri <- "https://api.nytimes.com/svc/movies/v2"
resource <- "/reviews/search.json"
query_params <- list("api-key" = nyt_apikey, query = movie_name)
# Send the HTTP Request to download the data
# Extract the content and convert it from JSON
response <- GET(paste0(base_uri, resource), query = query_params)
body <- fromJSON(content(response, "text"))
# What kind of data structure did this produce? A data frame? A list?
class(body)  # list
is.data.frame(body)  # FALSE
is.list(body)  # TRUE
# Manually inspect the returned data and identify the content of interest
# (which are the movie reviews).
# Use functions such as `names()`, `str()`, etc.
names(body)
names(body$results)
# Flatten the movie reviews content into a data structure called `reviews`
reviews <- flatten(body$results)
# From the most recent review, store the headline, short summary, and link to
# the full article, each in their own variables
first_review <- reviews[1, ]
headline <- first_review$headline
summary <- first_review$summary_short
link <- first_review$link.url
# Create a list of the three pieces of information from above.
# Print out the list.
review <- list(headline=headline, summary=summary, link=link)
# load relevant libraries
library("httr")
library("jsonlite")
# Be sure and check the README.md for complete instructions!
# Use `source()` to load your API key variable from the `apikey.R` file you made.
# Make sure you've set your working directory!
source("apikey.R")
# Create a variable `movie_name` that is the name of a movie of your choice.
movie_name <- "Star Wars"
# Construct an HTTP request to search for reviews for the given movie.
# The base URI is `https://api.nytimes.com/svc/movies/v2/`
# The resource is `reviews/search.json`
# See the interactive console for parameter details:
#   https://developer.nytimes.com/movie_reviews_v2.json
#
# You should use YOUR api key (as the `api-key` parameter)
# and your `movie_name` variable as the search query!
base_uri <- "https://api.nytimes.com/svc/movies/v2"
resource <- "/reviews/search.json"
query_params <- list("api-key" = nyt_apikey, query = movie_name)
# Send the HTTP Request to download the data
# Extract the content and convert it from JSON
response <- GET(paste0(base_uri, resource), query = query_params)
body <- fromJSON(content(response, "text"))
# What kind of data structure did this produce? A data frame? A list?
class(body)  # list
is.data.frame(body)  # FALSE
is.list(body)  # TRUE
# Manually inspect the returned data and identify the content of interest
# (which are the movie reviews).
# Use functions such as `names()`, `str()`, etc.
names(body)
names(body$results)
# Flatten the movie reviews content into a data structure called `reviews`
reviews <- flatten(body$results)
# From the most recent review, store the headline, short summary, and link to
# the full article, each in their own variables
first_review <- reviews[1, ]
headline <- first_review$headline
summary <- first_review$summary_short
link <- first_review$link.url
# Create a list of the three pieces of information from above.
# Print out the list.
review <- list(headline=headline, summary=summary, link=link)
# load relevant libraries
library("httr")
library("jsonlite")
# Be sure and check the README.md for complete instructions!
# Use `source()` to load your API key variable from the `apikey.R` file you made.
# Make sure you've set your working directory!
source("apikey.R")
# Create a variable `movie_name` that is the name of a movie of your choice.
movie_name <- "Star Wars"
# Construct an HTTP request to search for reviews for the given movie.
# The base URI is `https://api.nytimes.com/svc/movies/v2/`
# The resource is `reviews/search.json`
# See the interactive console for parameter details:
#   https://developer.nytimes.com/movie_reviews_v2.json
#
# You should use YOUR api key (as the `api-key` parameter)
# and your `movie_name` variable as the search query!
base_uri <- "https://api.nytimes.com/svc/movies/v2"
resource <- "/reviews/search.json"
query_params <- list("api-key" = nyt_apikey, query = movie_name)
# Send the HTTP Request to download the data
# Extract the content and convert it from JSON
response <- GET(paste0(base_uri, resource), query = query_params)
body <- fromJSON(content(response, "text"))
# What kind of data structure did this produce? A data frame? A list?
class(body)  # list
is.data.frame(body)  # FALSE
is.list(body)  # TRUE
# Manually inspect the returned data and identify the content of interest
# (which are the movie reviews).
# Use functions such as `names()`, `str()`, etc.
names(body)
names(body$results)
# Flatten the movie reviews content into a data structure called `reviews`
reviews <- flatten(body$results)
# From the most recent review, store the headline, short summary, and link to
# the full article, each in their own variables
first_review <- reviews[1, ]
headline <- first_review$headline
summary <- first_review$summary_short
link <- first_review$link.url
# Create a list of the three pieces of information from above.
# Print out the list.
review <- list(headline=headline, summary=summary, link=link)
first_review <- reviews[1, ]
headline <- first_review$headline
summary <- first_review$summary_short
link <- first_review$link.url
first_review <- reviews[1, ]
first_review <- reviews[1, ]
reviews <- flatten(body$results)
# load relevant libraries
library("httr")
library("jsonlite")
# Be sure and check the README.md for complete instructions!
# Use `source()` to load your API key variable from the `apikey.R` file you made.
# Make sure you've set your working directory!
source("apikey.R")
# Create a variable `movie_name` that is the name of a movie of your choice.
movie_name <- "Star Wars"
# Construct an HTTP request to search for reviews for the given movie.
# The base URI is `https://api.nytimes.com/svc/movies/v2/`
# The resource is `reviews/search.json`
# See the interactive console for parameter details:
#   https://developer.nytimes.com/movie_reviews_v2.json
#
# You should use YOUR api key (as the `api-key` parameter)
# and your `movie_name` variable as the search query!
base_uri <- "https://api.nytimes.com/svc/movies/v2"
resource <- "/reviews/search.json"
query_params <- list("api-key" = nyt_apikey, query = movie_name)
# load relevant libraries
library("httr")
library("jsonlite")
# Be sure and check the README.md for complete instructions!
# Use `source()` to load your API key variable from the `apikey.R` file you made.
# Make sure you've set your working directory!
source("apikey.R")
# Create a variable `movie_name` that is the name of a movie of your choice.
movie_name <- "Star Wars"
# Construct an HTTP request to search for reviews for the given movie.
# The base URI is `https://api.nytimes.com/svc/movies/v2/`
# The resource is `reviews/search.json`
# See the interactive console for parameter details:
#   https://developer.nytimes.com/movie_reviews_v2.json
#
# You should use YOUR api key (as the `api-key` parameter)
# and your `movie_name` variable as the search query!
base_uri <- "https://api.nytimes.com/svc/movies/v2"
resource <- "/reviews/search.json"
query_params <- list("api-key" = nyt_apikey, query = movie_name)
# Send the HTTP Request to download the data
# Extract the content and convert it from JSON
response <- GET(paste0(base_uri, resource), query = query_params)
body <- fromJSON(content(response, "text"))
# What kind of data structure did this produce? A data frame? A list?
class(body)  # list
is.data.frame(body)  # FALSE
is.list(body)  # TRUE
# Manually inspect the returned data and identify the content of interest
# (which are the movie reviews).
# Use functions such as `names()`, `str()`, etc.
names(body)
names(body$results)
# Flatten the movie reviews content into a data structure called `reviews`
reviews <- flatten(body$results)
# From the most recent review, store the headline, short summary, and link to
# the full article, each in their own variables
first_review <- reviews[1, ]
headline <- first_review$headline
summary <- first_review$summary_short
link <- first_review$link.url
# Create a list of the three pieces of information from above.
# Print out the list.
review <- list(headline=headline, summary=summary, link=link)
# Exercise 1: ggplot2 basics
# Install and load the `ggplot2` package
# You will also want to load `dplyr`
install.packages("ggplot2")
library("ggplot2")
library("dplyr")
# For this exercise you'll be working with the `diamonds` data set included in
# the ggplot2 library
# Use `?diamonds` to get more information about this data set (including the
# column descriptions. Also check the _column names_ and the _number of rows_
# in the data set
?diamonds
colnames(diamonds)
nrow(diamonds)
# This data set has A LOT of rows. To make things a bit more readable,
# use dplyr's `sample_n()` function to get a random 1000 rows from the data set
# Store this sample in a variable `diamonds_sample`
diamonds_sample <- sample_n(diamonds, 1000)
# Start by making a new `ggplot` with the `diamonds_sample` as the data (no
# geometry yet)
# What do you see? (What did you expect?)
ggplot(data = diamonds_sample)
# Draw a scatter plot (with point geometry) with for the `diamonds_sample` set,
# with the `carat` mapped to the x-position and `price` mapped to the y-position.
ggplot(data = diamonds_sample) +
geom_point(mapping = aes(x = carat, y = price))
# Draw the same plot as above, but color each of the points based on their
# clarity.
ggplot(data = diamonds_sample) +
geom_point(mapping = aes(x = carat, y = price, color = clarity))
# Draw the same plot as above, but for the entire `diamonds` data set. Note this
# may take a few seconds to generate.
ggplot(data = diamonds) +
geom_point(mapping = aes(x = carat, y = price, color = clarity))
# Draw another scatter plot for `diamonds_sample` of price (y) by carat (x),
# but with all of the dots colored "blue".
# Hint: you'll need to set the color channel, not map a value to it!
ggplot(data = diamonds_sample) +
geom_point(mapping = aes(x = carat, y = price), color = "blue")
# Draw a scatter plot for `diamonds_sample` of `price` by `carat`, where each
# point has an aesthetic _shape_ based on the diamond's `cut`.
ggplot(data = diamonds_sample) +
geom_point(mapping = aes(x = carat, y = price, shape = cut))
# Draw a scatter plot for `diamonds_sample` of *`cut`* by `carat`, where each
# point has an aesthetic _size_ based on the diamond's *`price`*
ggplot(data = diamonds_sample) +
geom_point(mapping = aes(x = carat, y = cut, size = price))
# Try coloring the above plot based on the diamond's price!
ggplot(data = diamonds_sample) +
geom_point(mapping = aes(x = carat, y = cut, size = price, color = price))
# Draw a line plot (with line geometry) for `diamonds_sample`. The x-position
# should be mapped to carat, y-position to price, and color to cut.
ggplot(data = diamonds_sample) +
geom_line(mapping = aes(x = carat, y = price, color = cut))
# That's kind of messy. Try using `smooth` geometry instead.
ggplot(data = diamonds_sample) +
geom_smooth(mapping = aes(x = carat, y = price, color = cut))
# Draw a plot with column geometry (a bar chart), mapping the diamond's `cut` to
# the x-axis and `price` to the y-axis. Note that by default, column geometry
# will us the "sum" of all of the y-values, so that the chart is actually of the
# TOTAL value of all of the diamonds of that cut!
ggplot(data = diamonds_sample) +
geom_col(mapping = aes(x = cut, y = price))
# Add an aesthetic property that will _fill_ each bar geometry based on the
# `clarity` of the diamonds.
# What kind of chart do you get?
ggplot(data = diamonds_sample) +
geom_col(mapping = aes(x = cut, y = price, fill = clarity))
# Draw a plot of the `diamonds_sample` data (price by carat), with both points
# for each diamond AND smoothed lines for each cut (hint: in a separate color)
# Give the points an `alpha` (transparency) of 0.3 to make the plot look nicer
ggplot(data = diamonds_sample) +
geom_point(mapping = aes(x = carat, y = price, color = cut), alpha = 0.3) +
geom_smooth(mapping = aes(x = carat, y = price, color = cut), se = FALSE)
## Bonus
# Draw a column chart of average diamond prices by clarity, and include
# "error bars" marking the standard error of each measurement.
#
# You can calculate standard error as the _standard deviation_ divided by the
# square root of the number of measurements (prices)
# Start by creating a data frame `clarity_summary` that includes summarized data
# for each clarity group. Your summary data should include the mean price and the
# standard error of the price.
clarity_summary <- diamonds %>%
group_by(clarity) %>%
summarize(mean = mean(price), sd = sd(price), se = sd / sqrt(length(price)))
# Then draw the plot. The error bars should stretch from the mean-error to the
# mean+error.
ggplot(data = clarity_summary, mapping = aes(x = clarity, y = mean)) +
geom_bar(mapping = aes(fill = clarity), stat = "identity") +
geom_errorbar(mapping = aes(ymin = (mean - se), ymax = (mean + se)))
setwd("~/info201/book-exercises/chapter-16-exercises/exercise-2")
# Exercise 2: advanced ggplot2 practice
# Install and load the `ggplot2` package
# install.packages('ggplot2')
library("ggplot2")
# For this exercise you will again be working with the `diamonds` data set.
# Use `?diamonds` to review details about this data set
?diamonds
## Position Adjustments
# Draw a column (bar) chart of diamonds cuts by price, with each bar filled by
# clarity. You should see a _stacked_ bar chart.
ggplot(data = diamonds) +
geom_col(mapping = aes(x = cut, y = price, fill = clarity))
# Draw the same chart again, but with each element positioned to "fill" the y axis
ggplot(data = diamonds) +
geom_col(mapping = aes(x = cut, y = price, fill = clarity), position = "fill")
# Draw the same chart again, but with each element positioned to "dodge" each other
ggplot(data = diamonds) +
geom_col(mapping = aes(x = cut, y = price, fill = clarity), position = "dodge")
# Draw a plot with point geometry with the x-position mapped to `cut` and the
# y-position mapped to `clarity`
# This creates a "grid" grouping the points
ggplot(data = diamonds) +
geom_point(mapping = aes(x = cut, y = clarity))
# Use the "jitter" position adjustment to keep the points from all overlapping!
# (This works a little better with a sample of diamond data, such as from the
# previous exercise).
ggplot(data = diamonds) +
geom_point(mapping = aes(x = cut, y = clarity), position = "jitter")
## Scales
# Draw a "boxplot" (with `geom_boxplot`) for the diamond's price (y) by color (x)
ggplot(data = diamonds) +
geom_boxplot(mapping = aes(x = color, y = price))
# This has a lot of outliers, making it harder to read. To fix this, draw the
# same plot but with a _logarithmic_ scale for the y axis.
ggplot(data = diamonds) +
geom_boxplot(mapping = aes(x = color, y = price)) +
scale_y_log10()
# For another version, draw the same plot but with `violin` geometry instead of
# `boxplot` geometry!
# How does the logarithmic scale change the data presentation?
ggplot(data = diamonds) +
geom_violin(mapping = aes(x = color, y = price)) +
scale_y_log10()
# Another interesting plot: draw a plot of the diamonds price (y) by carat (x),
# using a heatmap of 2d bins (geom_bin2d)
# What happens when you make the x and y channels scale logarithmically?
ggplot(data = diamonds) +
geom_bin2d(mapping = aes(x = carat, y = price)) +
scale_x_log10() +
scale_y_log10()
# Draw a scatter plot for the diamonds price (y) by carat (x). Color each point
# by the clarity (Remember, this will take a while. Use a sample of the diamonds
# for faster results)
ggplot(data = diamonds) +
geom_point(mapping = aes(x = carat, y = price, color = clarity))
# Change the color of the previous plot using a ColorBrewer scale of your choice.
# What looks nice?
ggplot(data = diamonds) +
geom_point(mapping = aes(x = carat, y = price, color = clarity)) +
scale_color_brewer(palette = "Spectral")
## Coordinate Systems
# Draw a bar chart with x-position and fill color BOTH mapped to cut
# For best results, SET the `width` of the geometry to be 1 (fill plot, no space
# between)
# TIP: You can save the plot to a variable for easier modifications
bar <- ggplot(data = diamonds) +
geom_bar(mapping = aes(x = cut, fill = cut), width = 1)
bar
# Draw the same chart, but with the coordinate system flipped
bar + coord_flip()
# Draw the same chart, but in a polar coordinate system. It's a Coxcomb chart!
bar + coord_polar()
## Facets
# Take the scatter plot of price by carat data (colored by clarity) and add
# _facets_ based on the diamond's `color`
ggplot(data = diamonds) +
geom_point(mapping = aes(x = carat, y = price, color = clarity)) +
scale_color_brewer(palette = "Spectral") +
facet_wrap(~ color)
## Saving Plots
# Use the `ggsave()` function to save the current (recent) plot to disk.
# Name the output file "my-plot.png".
# Make sure you've set the working directory!!
ggsave("my-plot.png")
